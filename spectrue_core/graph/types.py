# SPDX-License-Identifier: AGPL-3.0-or-later
# Copyright (c) 2024-2025 Spectrue Contributors
"""
ClaimGraph Type Definitions

Dataclasses for claim graph nodes, edges, and results.
"""

from __future__ import annotations

from dataclasses import dataclass, field
from enum import Enum
from typing import Dict, Literal


class EdgeRelation(str, Enum):
    """Edge relationship types for C-stage classification."""
    SUPPORTS = "supports"
    CONTRADICTS = "contradicts"
    DEPENDS_ON = "depends_on"
    ELABORATES = "elaborates"
    UNRELATED = "unrelated"


# Relation multipliers for weighted graph construction
RELATION_MULTIPLIERS: dict[EdgeRelation, float] = {
    EdgeRelation.SUPPORTS: 1.0,
    EdgeRelation.CONTRADICTS: 0.8,
    EdgeRelation.DEPENDS_ON: 0.9,
    EdgeRelation.ELABORATES: 0.5,
    EdgeRelation.UNRELATED: 0.0,
}

# Structural relations (used for in_structural_weight)
STRUCTURAL_RELATIONS: set[EdgeRelation] = {
    EdgeRelation.SUPPORTS,
    EdgeRelation.DEPENDS_ON,
}


@dataclass
class ClaimPreGraphMeta:
    """Pre-graph metadata computed from embeddings and positional priors."""
    claim_id: str
    position_rank: int
    pos_prior: float
    support_mass: float
    novelty: float
    uncertainty_proxy: float
    importance_prior: float = 0.0
    harm_prior: float = 0.0
    node_prior: float = 0.0


@dataclass
class ClaimPostGraphMeta:
    """Post-graph metadata used for explainability and tracing only."""
    pagerank: float = 0.0
    centrality_rank: int = -1
    selected: bool = False
    selection_gain: float = 0.0
    selection_cost: float = 0.0
    debug: Dict[str, float] = field(default_factory=dict)


@dataclass
class ClaimNode:
    """
    Claim node for graph construction.
    
    Each node must have stable identifiers for traceability:
    claim_id → section_id → anchor
    """
    claim_id: str           # e.g., "c1" (stable identifier)
    text: str               # Claim text (normalized_text preferred)
    claim_type: str         # "core", "numeric", "timeline", "attribution", "sidefact"
    section_id: str         # Section identifier or "main" (for adjacency)
    anchor: str             # Offset or short quote pointer (first 50 chars)
    importance: float       # 0.0-1.0
    topic_key: str          # Topic grouping key
    harm_potential: int = 1 # Harm Potential (1-5)
    
    # For deduplication
    text_hash: str = ""     # Hash of normalized text for caching
    
    @classmethod
    def from_claim_dict(cls, claim: dict, index: int = 0) -> "ClaimNode":
        """Create ClaimNode from legacy claim dict."""
        import hashlib
        
        text = claim.get("normalized_text") or claim.get("text") or ""
        text_hash = hashlib.sha256(text.lower().encode()).hexdigest()[:16]
        
        return cls(
            claim_id=claim.get("id") or f"c{index + 1}",
            text=text,
            claim_type=claim.get("type", "core"),
            section_id=claim.get("section_id", "main"),
            anchor=text[:50] if text else "",
            importance=float(claim.get("importance", 0.5)),
            topic_key=claim.get("topic_key", "Other"),
            harm_potential=int(claim.get("harm_potential", 1)),
            text_hash=text_hash,
        )


@dataclass
class CandidateEdge:
    """
    B-stage output: candidate edge between two claims.
    
    Generated by embedding similarity, adjacency, or keyword overlap.
    """
    src_id: str
    dst_id: str
    reason: Literal["sim", "adjacent", "keyword"]
    sim_score: float        # 0.0-1.0 (embeddings) or Jaccard (keywords)
    same_section: bool
    cross_topic: bool = False  # Edge crosses topic boundaries


@dataclass
class TypedEdge:
    """
    C-stage output: classified edge with relation and score.
    
    Only edges with relation != UNRELATED and score >= τ are kept.
    """
    src_id: str
    dst_id: str
    relation: EdgeRelation
    score: float            # 0.0-1.0 confidence
    rationale_short: str    # 10-25 words, logs only
    evidence_spans: str     # Key text supporting classification, ≤25 words
    cross_topic: bool = False  # Preserved from CandidateEdge
    
    def to_trace_dict(self) -> dict:
        """Convert to dict for tracing."""
        return {
            "src": self.src_id,
            "dst": self.dst_id,
            "rel": self.relation.value,
            "score": round(self.score, 2),
        }


@dataclass
class RankedClaim:
    """
    Graph ranking output: claim with centrality and structural scores.
    """
    claim_id: str
    centrality_score: float         # PageRank score
    in_structural_weight: float     # Sum of incoming supports + depends_on
    in_contradict_weight: float     # Sum of incoming contradicts
    is_key_claim: bool              # Selected as top-K
    
    def to_trace_dict(self) -> dict:
        """Convert to dict for tracing."""
        return {
            "id": self.claim_id,
            "centrality": round(self.centrality_score, 4),
            "structural": round(self.in_structural_weight, 2),
        }


@dataclass
class DedupeResult:
    """
    Deduplication result with canonical claims and mapping.
    """
    canonical_claims: list[ClaimNode]
    dedup_map: dict[str, list[str]]  # canonical_id -> [merged_ids]
    reduction_ratio: float           # original_count / canonical_count


@dataclass
class GraphResult:
    """
    Final ClaimGraph result.
    
    Includes key claims, metrics, and optional disable reason.
    """
    # Results
    key_claims: list[RankedClaim] = field(default_factory=list)
    all_ranked: list[RankedClaim] = field(default_factory=list)
    typed_edges: list[TypedEdge] = field(default_factory=list)
    
    # Metrics
    claims_count_raw: int = 0
    claims_count_dedup: int = 0
    candidate_edges_count: int = 0
    typed_edges_kept_count: int = 0
    kept_ratio: float = 0.0
    # Topic-aware metrics
    within_topic_edges_count: int = 0
    cross_topic_edges_count: int = 0
    kept_ratio_within_topic: float = 0.0
    
    typed_edges_by_relation: dict[str, int] = field(default_factory=dict)
    
    # Budget tracking
    latency_ms: int = 0
    cost_usd: float = 0.0
    
    # Disable state
    disabled: bool = False
    disabled_reason: str | None = None  # "budget_exceeded_preflight" | "quality_gate_failed"
    fallback_used: bool = False  # Fallback Key Claims used when graph disabled
    sparse_graph: bool = False  # Graph valid but has few/no edges (kept_ratio < min)
    confidence_scalar: float = 1.0

    # Pre/Post metadata and similarity edges (post-graph metadata is explainability-only)
    pre_meta: dict[str, ClaimPreGraphMeta] = field(default_factory=dict)
    post_meta: dict[str, ClaimPostGraphMeta] = field(default_factory=dict)
    sim_edges: list[tuple[str, str, float]] = field(default_factory=list)
    mst_edges: list[tuple[str, str, float]] = field(default_factory=list)
    selection_trace: list[dict[str, float]] = field(default_factory=list)
    
    @property
    def key_claim_ids(self) -> list[str]:
        """Get list of key claim IDs."""
        return [c.claim_id for c in self.key_claims]
    
    def get_ranked_by_id(self, claim_id: str) -> RankedClaim | None:
        """Get RankedClaim by claim_id (Layer 2)."""
        for c in self.all_ranked:
            if c.claim_id == claim_id:
                return c
        return None
    
    @property
    def high_tension_claims(self) -> list[RankedClaim]:
        """
        Claims with significant incoming contradictions (Layer 3).
        
        Returns top 5 claims sorted by tension score descending.
        Threshold is hardcoded at 0.5; use config for runtime tuning.
        """
        return sorted(
            [c for c in self.all_ranked if c.in_contradict_weight > 0.5],
            key=lambda c: c.in_contradict_weight,
            reverse=True
        )[:5]
    
    def get_tension_score(self, claim_id: str) -> float:
        """Get tension score (in_contradict_weight) for a claim (Layer 3)."""
        ranked = self.get_ranked_by_id(claim_id)
        return ranked.in_contradict_weight if ranked else 0.0
    
    def to_trace_dict(self) -> dict:
        """Convert to dict for tracing."""
        return {
            "enabled": not self.disabled,
            "disabled_reason": self.disabled_reason,
            "fallback_used": self.fallback_used,
            "claims_count_raw": self.claims_count_raw,
            "claims_count_dedup": self.claims_count_dedup,
            "candidate_edges_count": self.candidate_edges_count,
            "typed_edges_kept_count": self.typed_edges_kept_count,
            "kept_ratio": round(self.kept_ratio, 3),
            "within_topic_edges_count": self.within_topic_edges_count,
            "cross_topic_edges_count": self.cross_topic_edges_count,
            "kept_ratio_within_topic": round(self.kept_ratio_within_topic, 3),
            "typed_edges_by_relation": self.typed_edges_by_relation,
            "key_claims_ids_and_scores": [c.to_trace_dict() for c in self.key_claims[:12]],
            "sample_edges": [e.to_trace_dict() for e in self.typed_edges[:10]],
            "latency_ms": self.latency_ms,
            "cost_usd": round(self.cost_usd, 4),
            "confidence_scalar": round(self.confidence_scalar, 3),
        }
