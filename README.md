# Spectrue Engine

<p align="center">
  <strong>Open Source AI Fact-Checking Core</strong>
</p>

<p align="center">
  <a href="LICENSE"><img src="https://img.shields.io/badge/License-AGPL_v3-blue.svg" alt="License: AGPL v3"></a>
  <a href="https://www.python.org/downloads/"><img src="https://img.shields.io/badge/python-3.10+-blue.svg" alt="Python 3.10+"></a>
  <a href="https://github.com/wivanw/spectrue-engine/actions"><img src="https://img.shields.io/github/actions/workflow/status/wivanw/spectrue-engine/ci.yml?branch=main&label=CI" alt="CI Status"></a>
  <a href="https://codecov.io/gh/wivanw/spectrue-engine"><img src="https://img.shields.io/codecov/c/github/wivanw/spectrue-engine" alt="Coverage"></a>
  <a href="https://github.com/wivanw/spectrue-engine/releases"><img src="https://img.shields.io/github/v/release/wivanw/spectrue-engine?include_prereleases" alt="Release"></a>
</p>

<p align="center">
  The transparent, hallucination-resistant analysis engine behind Spectrue.<br>
  Multi-agent fact-checking â€¢ Web-based verification â€¢ Deep analysis
</p>

<p align="center">
  <a href="#-features">Features</a> â€¢
  <a href="#-installation">Installation</a> â€¢
  <a href="#-usage">Usage</a> â€¢
  <a href="docs/API.md">API Docs</a> â€¢
  <a href="docs/ARCHITECTURE.md">Architecture</a> â€¢
  <a href="#-contributing">Contributing</a>
</p>

---


## âœ¨ Features

- **Claim-Centric Orchestration**: Each claim gets metadata-driven verification routing
- **Progressive Widening Search**: Cost-aware phases with early exit when evidence is sufficient
- **Multi-Agent Architecture**: Orchestrates Oracle, Analyst, and Verifier agents
- **Hallucination Resistance**: Strict source verification with 'Aletheia-X' prompts
- **Smart Waterfall Search**: Optimized strategy (Oracle â†’ Tier 1 â†’ Deep Dive)
- **Content-Aware Localization**: Detects content language and uses native sources
- **RGBA Analysis**: Returns orthogonal scores for Danger, Veracity, Honesty, and Explainability
- **Fail-Soft Architecture**: Graceful degradation on component failures

## ðŸ”„ Verification Pipeline

The core verification process follows this pipeline:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     INPUT (URL or Text)                         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. CLAIM EXTRACTION + METADATA                                 â”‚
â”‚     â€¢ LLM extracts atomic verifiable claims                     â”‚
â”‚     â€¢ Each claim gets ClaimMetadata:                            â”‚
â”‚       - verification_target: reality|attribution|existence|none â”‚
â”‚       - claim_role: core|support|context|meta                   â”‚
â”‚       - search_locale_plan: primary + fallback languages        â”‚
â”‚       - retrieval_policy: allowed evidence channels             â”‚
â”‚       - metadata_confidence: high|medium|low                    â”‚
â”‚     â€¢ "Search Strategist" approach: LLM reasons about           â”‚
â”‚       intent, authority, language, risks (Chain of Thought)     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. ORCHESTRATOR â†’ EXECUTION PLAN                               â”‚
â”‚     â€¢ ClaimOrchestrator builds ExecutionPlan per claim          â”‚
â”‚     â€¢ Phases based on metadata:                                 â”‚
â”‚       - Phase A: Primary locale, authoritative sources, k=3    â”‚
â”‚       - Phase B: +local media, advanced depth, k=5             â”‚
â”‚       - Phase C: Fallback locale (e.g., English), k=3          â”‚
â”‚       - Phase D: All channels, deep search, k=7                â”‚
â”‚       - Phase A-light: Fail-open for low-confidence, k=2       â”‚
â”‚     â€¢ verification_target=none â†’ 0 phases (skip search)        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. ORACLE CHECK (Hybrid Mode)                                  â”‚
â”‚     â€¢ Smart Validator: LLM compares claim vs fact-check         â”‚
â”‚     â€¢ JACKPOT (>0.9): Stop pipeline immediately                 â”‚
â”‚     â€¢ EVIDENCE (0.5-0.9): Add to evidence pack (Tier A)         â”‚
â”‚     â€¢ MISS (<0.5): Proceed to web search                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. PROGRESSIVE WIDENING (PhaseRunner)                          â”‚
â”‚     â€¢ Execute phases sequentially: A â†’ B â†’ C â†’ D                â”‚
â”‚     â€¢ After each phase: check evidence sufficiency              â”‚
â”‚     â€¢ Sufficiency Rules:                                        â”‚
â”‚       Rule 1: 1 authoritative source with quote = STOP          â”‚
â”‚       Rule 2: 2 independent reputable sources = STOP            â”‚
â”‚       Rule 3: 1 origin source (for attribution) = STOP          â”‚
â”‚     â€¢ Early exit: Skip remaining phases when sufficient         â”‚
â”‚     â€¢ Parallel execution within each phase (semaphore-limited)  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. STANCE CLUSTERING                                           â”‚
â”‚     â€¢ LLM maps search results to claims                         â”‚
â”‚     â€¢ Assigns stance: support | contradict | context            â”‚
â”‚     â€¢ Calculates relevance score per source-claim pair          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. EVIDENCE PACK BUILDING                                      â”‚
â”‚     â€¢ Structures evidence for LLM scorer                        â”‚
â”‚     â€¢ Computes per-claim metrics:                               â”‚
â”‚       - independent_domains, primary_present, official_present  â”‚
â”‚       - stance_distribution, coverage                           â”‚
â”‚     â€¢ Sets confidence constraints based on evidence quality     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  7. WEIGHTED RGBA SCORING                                       â”‚
â”‚     â€¢ Quote Highlighting: "ðŸ“Œ QUOTE" markers for key evidence   â”‚
â”‚     â€¢ Generates verdict per-claim with semantic scale           â”‚
â”‚     â€¢ Aggregates with role-based weighting:                     â”‚
â”‚       - CORE claims: weight=1.0                                 â”‚
â”‚       - CONTEXT claims (horoscopes, predictions): weight=0.0    â”‚
â”‚       - ATTRIBUTION claims: weight=0.7                          â”‚
â”‚     â€¢ Result: Context claims don't dilute factual scores        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                              â”‚
                              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                       OUTPUT (Result)                           â”‚
â”‚  verified_score, danger_score, style_score, explainability,     â”‚
â”‚  rationale, claim_verdicts, sources, phase_trace                â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ðŸŽ¯ Claim-Centric Orchestration (M80)

The engine uses metadata-driven routing to optimize verification:

### ClaimMetadata

Each claim is enriched with metadata at extraction time:

```python
ClaimMetadata(
    verification_target="reality",  # What to verify
    claim_role="core",              # Role in document
    check_worthiness=0.9,           # Priority (0-1)
    search_locale_plan=SearchLocalePlan(
        primary="en",
        fallback=["uk"]
    ),
    retrieval_policy=RetrievalPolicy(
        channels_allowed=["authoritative", "reputable_news"]
    ),
    metadata_confidence="high"
)
```

### Verification Targets

| Target | Description | Example |
|--------|-------------|---------|
| `reality` | Verify factual accuracy | "Biden won 2024" |
| `attribution` | Verify who said what | "Elon Musk said..." |
| `existence` | Verify source/doc exists | "According to the report..." |
| `none` | Not verifiable (skip) | Horoscopes, predictions |

### Evidence Sufficiency

The engine stops searching when one of these rules is satisfied:

| Rule | Condition | Example |
|------|-----------|---------|
| **Rule 1** | 1 authoritative source (gov/edu) with quote | CDC confirms vaccine safety |
| **Rule 2** | 2 independent reputable sources with quotes | Reuters + AP both report |
| **Rule 3** | 1 origin source (for attribution claims) | Original tweet found |

## ðŸ§  Design Philosophy

### LLM as Search Strategist

**When working with search system code, rely on LLM reasoning rather than heuristics or hardcoded examples for better results.**

This means:
- âŒ **NO hardcoded `if/else`** for "if science â†’ search English"
- âŒ **NO domain-specific heuristics** like keyword lists
- âœ… **LLM reasons** about intent, authority, language, risks
- âœ… **Chain of Thought prompts** force LLM to explain before generating
- âœ… **Python only for**: filtering, caps enforcement, API calls

**Why?** LLM generalizes to new domains (K-Pop â†’ Korean, Cricket â†’ Hindi) without code changes.

### Fail-Soft Architecture

The engine is designed to gracefully degrade:
- **Low confidence metadata**: Inject Phase A-light (minimal search)
- **Search failure**: Continue to next phase, don't crash
- **LLM failure**: Return partial results with reduced confidence

## ðŸ“‹ Requirements

- **Python**: 3.10â€“3.12 (3.10+ supported)
- **Dependencies**: See [pyproject.toml](pyproject.toml)

### Required API Keys

| Key | Purpose | Required |
|-----|---------|----------|
| `OPENAI_API_KEY` | LLM analysis (GPT-5) | Yes |
| `TAVILY_API_KEY` | Web search | Yes |
| `GOOGLE_FACT_CHECK_KEY` | Oracle fact-check | Optional |

## ðŸš€ Installation

### From PyPI (when published)
```bash
pip install spectrue-engine
```

### From GitHub (Latest)
```bash
pip install git+https://github.com/wivanw/spectrue-engine.git
```

### For Development
```bash
git clone https://github.com/wivanw/spectrue-engine.git
cd spectrue-engine
pip install -e ".[dev]"
```

## ðŸ’¡ Usage

### Basic Usage

```python
from spectrue_core.engine import SpectrueEngine
from spectrue_core.config import SpectrueConfig

# Initialize configuration
config = SpectrueConfig(
    openai_api_key="sk-...",
    tavily_api_key="tvly-..."
)

# Initialize engine
engine = SpectrueEngine(config)

# Analyze a claim
result = await engine.analyze_text(
    text="NASA discovered a new moon orbiting Earth.",
    lang="en"
)

print(f"Veracity: {result['verified_score']:.2f}")
print(f"Confidence: {result['confidence_score']:.2f}")
print(f"Analysis: {result['rationale']}")
```

### With Claim Orchestration (M80)

```python
from spectrue_core.verification.orchestrator import ClaimOrchestrator
from spectrue_core.verification.phase_runner import PhaseRunner
from spectrue_core.verification.execution_plan import BudgetClass

# Build execution plan
orchestrator = ClaimOrchestrator()
plan = orchestrator.build_execution_plan(claims, BudgetClass.STANDARD)

# Run progressive widening
runner = PhaseRunner(search_manager, max_concurrent=3)
evidence = await runner.run_all_claims(claims, plan)

# Evidence is keyed by claim_id
for claim_id, sources in evidence.items():
    print(f"Claim {claim_id}: {len(sources)} sources found")
```

### Checking Evidence Sufficiency

```python
from spectrue_core.verification.sufficiency import evidence_sufficiency
from spectrue_core.schema.claim_metadata import VerificationTarget

result = evidence_sufficiency(
    claim_id="c1",
    sources=search_results,
    verification_target=VerificationTarget.REALITY
)

if result.status == "sufficient":
    print(f"âœ“ Stopped early: {result.rule_matched}")
else:
    print(f"Continue searching: {result.reason}")
```

## ðŸ—ï¸ Architecture

```
spectrue_core/
â”œâ”€â”€ engine.py              # Main entry point
â”œâ”€â”€ config.py              # Configuration management
â”œâ”€â”€ runtime_config.py      # Feature flags & tunables
â”‚
â”œâ”€â”€ agents/                # LLM agents
â”‚   â””â”€â”€ skills/            # Modular skills
â”‚       â”œâ”€â”€ claims.py      # Claim extraction + metadata
â”‚       â”œâ”€â”€ clustering.py  # Stance clustering
â”‚       â”œâ”€â”€ scoring.py     # Evidence scoring
â”‚       â””â”€â”€ relevance.py   # Semantic gating
â”‚
â”œâ”€â”€ schema/                # Data types
â”‚   â”œâ”€â”€ claim_metadata.py  # M80: ClaimMetadata, VerificationTarget
â”‚   â”œâ”€â”€ claims.py          # ClaimUnit, Assertion
â”‚   â”œâ”€â”€ verdict.py         # StructuredVerdict
â”‚   â””â”€â”€ serialization.py   # Canonical JSON-safe serialization helpers
â”‚
â”œâ”€â”€ verification/          # Verification pipeline
â”‚   â”œâ”€â”€ pipeline.py        # Main orchestrator
â”‚   â”œâ”€â”€ orchestrator.py    # M80: ClaimOrchestrator
â”‚   â”œâ”€â”€ execution_plan.py  # M80: Phase, ExecutionPlan
â”‚   â”œâ”€â”€ phase_runner.py    # M80: PhaseRunner
â”‚   â”œâ”€â”€ sufficiency.py     # M80: Evidence sufficiency
â”‚   â”œâ”€â”€ rgba_aggregation.py# M80: Weighted RGBA
â”‚   â”œâ”€â”€ evidence.py        # Evidence pack builder
â”‚   â”œâ”€â”€ evidence_pack.py   # Data structures
â”‚   â””â”€â”€ search_mgr.py      # Search orchestration
â”‚
â”œâ”€â”€ graph/                 # ClaimGraph (M72)
â”‚   â”œâ”€â”€ claim_graph.py     # Build pipeline orchestration
â”‚   â”œâ”€â”€ candidates.py      # B-stage: candidate generation
â”‚   â”œâ”€â”€ ranking.py         # Ranking (PageRank)
â”‚   â”œâ”€â”€ quality_gates.py   # Gate checks (kept_ratio bounds)
â”‚   â””â”€â”€ embedding_util.py  # Embedding client
â”‚
â”œâ”€â”€ utils/                 # Utilities
â”‚   â”œâ”€â”€ trace.py           # Debug tracing (safe payloads)
â”‚   â””â”€â”€ trust_utils.py     # Source reputation
â”‚
â””â”€â”€ tools/                 # External APIs
    â”œâ”€â”€ search_tool.py     # Tavily API
    â”œâ”€â”€ google_fact_check.py  # Google Fact Check
    â””â”€â”€ google_cse_search.py  # Google Custom Search
```

## ðŸ”§ Configuration

### Environment Variables

```bash
# Required
export OPENAI_API_KEY="sk-..."
export TAVILY_API_KEY="tvly-..."

# Optional
export GOOGLE_FACT_CHECK_KEY="..."  # For Oracle
export SPECTRUE_ENGINE_DEBUG=true   # Enable debug logging

# Feature Flags
export FEATURE_CLAIM_ORCHESTRATION=true  # Enable M80 orchestration
export M80_MAX_CONCURRENT_SEARCHES=3     # Parallel search limit

# Trace Configuration
export TRACE_SAFE_PAYLOADS=true    # Sanitize logs (default: true)
export TRACE_MAX_HEAD_CHARS=120    # Truncation limit
```

### Programmatic Configuration

```python
config = SpectrueConfig(
    openai_api_key="...",           # Required for analysis
    tavily_api_key="...",           # Required for search
    openai_model="gpt-5",            # Model for analysis
    min_confidence_threshold=0.7,   # Minimum confidence
    max_search_depth=3              # Search recursion depth
)
```

## ðŸ§ª Testing

```bash
# Run offline core suite (no network, no secrets)
export SPECTRUE_TEST_OFFLINE=1
pytest tests/unit tests/test_*.py \
  tests/integration/test_m80_orchestration.py \
  tests/integration/test_m81_calibration.py \
  tests/integration/test_verification_pipeline.py

# Run specific test suite
pytest tests/unit/test_orchestrator.py -v
pytest tests/unit/test_sufficiency.py -v
pytest tests/integration/test_m80_orchestration.py -v

# With coverage
pytest --cov=spectrue_core
```

**Current Test Coverage**: 59 orchestration tests + existing test suite

## ðŸ¤ Contributing

We welcome contributions! Please see [CONTRIBUTING.md](CONTRIBUTING.md) for guidelines.

**Quick Start:**
1. Fork the repository
2. Create a feature branch (`git checkout -b feature/amazing-feature`)
3. Make your changes with tests
4. Run tests: `pytest`
5. Lint: `ruff check .`
6. Submit a Pull Request

## ðŸ§° Open Source Maintainer Checklist

Use this checklist to keep the engine â€œopen-source readyâ€ (reproducible, reviewable, and stable for external users).

### Releases
- Update `CHANGELOG.md` (Keep a Changelog; one entry per release).
- Bump version in `pyproject.toml` following SemVer (breaking changes require a major bump).
- Tag the release and ensure CI is green on the tag.

### Tests (No-Network Core Suite)
- Keep a **core test suite** that runs without network access or secrets (unit + key integration tests).
- Any test that requires network must be explicitly isolated/marked and not part of the core suite.
- Add regression tests for bug fixes, especially for pipeline/search â€œshapeâ€ changes.

### Documentation
- Keep `docs/ARCHITECTURE.md` consistent with the current module structure and terminology/contracts (Document, Claim, Claim metadata, ClaimRole, VerificationTarget, SearchLocalePlan, RetrievalPolicy, Evidence, Sufficiency).
- Update `docs/API.md` when public-facing data contracts change.
- Prefer additive/backward-compatible schema changes; document migrations when unavoidable.

### Compatibility & Contracts
- Do not break public entrypoints/imports; use thin wrappers + re-exports when refactoring.
- Keep canonical shapes stable (e.g. search returns `(context_text, sources)`; normalize provider fields like `linkâ†’url`, `snippetâ†’content`).

### Security & Licensing
- Never commit secrets or trace artifacts with sensitive content.
- Ensure new files follow the repositoryâ€™s license header pattern and do not introduce incompatible code/licenses.

## ðŸ“œ License

This project is licensed under the **GNU Affero General Public License v3 (AGPLv3)**.

This means:
- âœ… You can use it in your projects
- âœ… You can modify and distribute it
- âš ï¸ If you run a modified version as a service, you **must** share your source code

See [LICENSE](LICENSE) for full details.

## ðŸ›¡ï¸ Security

Found a security issue? Please email **wivanw@gmail.com** instead of opening a public issue.

See [SECURITY.md](SECURITY.md) for our security policy.

## ðŸ“ž Support

- **Issues**: [GitHub Issues](https://github.com/wivanw/spectrue-engine/issues)
- **Discussions**: [GitHub Discussions](https://github.com/wivanw/spectrue-engine/discussions)
- **Email**: wivanw@gmail.com

## ðŸ™ Acknowledgments

Built with support from:
- NGI Zero Commons Fund
- Open Source community

---

**Made with â¤ï¸ for transparency in AI**
